{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Tracing with Gemini 2.0 Flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import google.generativeai as gemini\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "mlflow.set_experiment(\"gemini-tracing\")\n",
    "\n",
    "mlflow.gemini.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"MLflow is an open-source platform to manage the machine learning lifecycle. It's designed to address the challenges of developing, deploying, and managing machine learning models, including tracking experiments, packaging code for reproducibility, and deploying models to various environments.\\n\\nThink of it as a central hub that helps data scientists and machine learning engineers collaborate and streamline their workflows.\\n\\nHere's a breakdown of its key features and functionalities:\\n\\n**Key Components of MLflow:**\\n\\n* **MLflow Tracking:**\\n    * **Purpose:** Records and queries experiments:\\n        * **Parameters:** Hyperparameters used in the model training.\\n        * **Metrics:** Evaluation scores like accuracy, loss, F1 score.\\n        * **Artifacts:** Model files, datasets, visualizations.\\n        * **Source Code:** Git commit ID, code used to train the model.\\n    * **Benefit:** Allows for easy comparison of different experiments, promotes reproducibility, and helps you understand why a particular model performed well. It's like a comprehensive experiment logbook.\\n* **MLflow Projects:**\\n    * **Purpose:** Packages code in a reproducible way, ensuring that models can be run consistently on different platforms.\\n    * **Benefit:** Makes it easy to share your machine learning code with colleagues, run on cloud environments, and reproduce results without struggling with environment issues.\\n* **MLflow Models:**\\n    * **Purpose:** Provides a standard format for packaging machine learning models, making them easily deployable to different platforms.\\n    * **Benefit:** Simplifies the deployment process and allows for greater flexibility, enabling you to deploy models to cloud services, on-premise servers, or embedded devices. You can manage various versions of your model.\\n* **MLflow Registry:**\\n    * **Purpose:** A centralized repository for managing the lifecycle of your models, including versioning, staging, and access control.\\n    * **Benefit:** Enables collaboration, promotes governance and control over deployed models, and tracks model lineage. You can easily manage the transition of models from development to production.\\n\\n**Key Benefits of Using MLflow:**\\n\\n* **Reproducibility:** Ensures that experiments and models can be reproduced consistently.\\n* **Collaboration:** Facilitates collaboration among team members by providing a centralized platform.\\n* **Experiment Tracking:** Simplifies the process of organizing, tracking, and comparing experiments.\\n* **Model Management:** Makes it easy to package, deploy, and manage models.\\n* **Deployment Flexibility:** Allows models to be deployed to a variety of platforms.\\n* **Open Source:** Free to use and highly customizable.\\n* **Integration:** Integrates with various machine learning frameworks (e.g., TensorFlow, PyTorch, scikit-learn) and cloud platforms.\\n\\n**In simple terms, MLflow helps you answer questions like:**\\n\\n* \\\"What parameters did I use for this model?\\\"\\n* \\\"Which model performed the best?\\\"\\n* \\\"How can I reproduce this model training?\\\"\\n* \\\"How do I deploy this model to production?\\\"\\n\\n**Who uses MLflow?**\\n\\nMLflow is used by a variety of users, including:\\n\\n* **Data Scientists:** For managing experiments, tracking model performance, and reproducing results.\\n* **Machine Learning Engineers:** For packaging, deploying, and monitoring models.\\n* **AI/ML Teams:** For collaborating and building end-to-end machine learning pipelines.\\n\\n**In Conclusion:**\\n\\nMLflow is a powerful tool that addresses the complexities of managing the machine learning lifecycle. By providing a structured approach to experiment tracking, code packaging, and model deployment, it helps teams build and deploy machine learning models more efficiently and effectively. It promotes collaboration, reproducibility, and streamlines the process from experimentation to production.\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\"\n",
      "            }\n",
      "          ],\n",
      "          \"avg_logprobs\": -0.5386065737739283\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 6,\n",
      "        \"candidates_token_count\": 764,\n",
      "        \"total_token_count\": 770\n",
      "      }\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gemini.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "model = gemini.GenerativeModel(\"gemini-2.0-flash-exp\")\n",
    "response = model.generate_content(\"What is MLflow?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Calling Example\n",
    "\n",
    "## Using the Gemini SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"The tip for a $187.32 bill with a 22% tip is $41.21.\\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ],\n",
       "          \"avg_logprobs\": -0.0004010262366916452\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 189,\n",
       "        \"candidates_token_count\": 28,\n",
       "        \"total_token_count\": 217\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the tool/function that Gemini can call\n",
    "def calculate_tip(bill_amount: float, tip_percentage: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the tip amount based on the bill amount and tip percentage.\n",
    "\n",
    "    Args:\n",
    "        bill_amount (float): The total bill amount.\n",
    "        tip_percentage (float): The percentage of the bill to be given as a tip.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated tip amount.\n",
    "    \"\"\"\n",
    "    return bill_amount * (tip_percentage / 100)\n",
    "\n",
    "model = gemini.GenerativeModel(\"gemini-2.0-flash-exp\", tools=[calculate_tip])\n",
    "chat = model.start_chat(enable_automatic_function_calling=True)\n",
    "\n",
    "response = chat.send_message(\"What is the tip for a $187.32 bill with a 22% tip?\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the OpenAI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tip amount is $41.21\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "# Define the function schema in OpenAI format\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculate_tip\",\n",
    "            \"description\": \"Calculate the tip amount based on the bill amount and tip percentage\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"bill_amount\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The total bill amount\"\n",
    "                    },\n",
    "                    \"tip_percentage\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The percentage of the bill to be given as a tip\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"bill_amount\", \"tip_percentage\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def calculate_tip(bill_amount: float, tip_percentage: float) -> float:\n",
    "    return bill_amount * (tip_percentage / 100)\n",
    "\n",
    "# Make the request\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is the tip for a $187.32 bill with a 22% tip?\"}\n",
    "    ],\n",
    "    tools=tools,\n",
    "    tool_choice=\"required\",\n",
    ")\n",
    "\n",
    "# Handle the function call\n",
    "if response.choices[0].message.tool_calls:\n",
    "    tool_call = response.choices[0].message.tool_calls[0]\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    \n",
    "    # Execute the function\n",
    "    result = calculate_tip(\n",
    "        bill_amount=function_args[\"bill_amount\"],\n",
    "        tip_percentage=function_args[\"tip_percentage\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"The tip amount is ${result:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
